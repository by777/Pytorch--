> RCNN（Regions with CNN Features）

# 开山之作：RCNN3

+ 发表于：CVPR 2014
+ 检测率（PASCAL VOC）:从35.1% 提升到了 53.7%

具体流程：

1. **候选区域生成**。采用Region Proposal提取候选区域，例如Selective Search。先将候选区域分割成小区域，然后合并包含同一物体可能性高的区域，并输出。这一步需要提取约2000个候选区域。在提取完后，还需要对每一个区域归一化。得到固定大小的图像。
2. **CNN特征提取**。利用CNN得到固定维度的特征输出。
3. **SVM分类器**。利用线性二分类器对输出的特征分类，得到是否属于此类的结果，并且采用**难样本挖掘**来平衡正负样本的不平衡。
4. **位置精修**。通过一个回归器，对特征边界回归得到更精确的目标区域。

# 端到端：Fast RCNN

在RCNN后，SPPNet解决了重复卷积计算与固定输出尺度的两个问题。

在2015年，提出了端到端的Fast RCNN，基于VGG16，训练速度上比RCNN快了近9倍，测试速度上快了213倍，在VOC 2012上达到了68.4%的准确率。

相比于RCNN，Fast RCNN主要有以下改进：

+ **共享卷积**。将整幅图送到CNN进行区域生成，而不是像RCNN那样一个个的候选区域，虽然仍采用Selective Search方法，但共享卷积使得计算量大大减少。
+ **RoI Pooling**。利用特征池化（RoI Pooling）的方法进行特征尺度变换，这种方法可以有任意大小的输入，使得训练过程更加灵活准确。
+ **多任务损失**。将分类和回归任务放到一起训练，并且为了避免SVM分类器带来的单独训练与速度慢的缺点，使用了softmax函数分类。

**缺点**：Seective Search消耗了2~3秒，远大于特征提取的0.2秒。

# 走向实时：Faster RCNN

+ 发表于 NIPS 2015
+ 创新点：提出了RPN（Region Proposal Network）
+ Anchor-base
+ 速度：17 FPS
+ 在VOC 2012测试集上准确率：70.4%

# Anchor

Anchor可以看作图像上许多固定大小与宽高的方框，由于需要检测的物体本身也都是一个个宽高不同的方框，因此Faster RCNN将Anchor动作强先验的知识，接下来只需要将Anchor与真实物体匹配，进行分类与位置的微调而已。相比于没有Anchor的物体检测算法，这样无疑降低了网络收敛的难度。
