# 发展历程
在利用深度学习做物体检测之前。传统算法对物体的检测通常分为`区域选取` `特征提取` `特征分类`这3个阶段。

1. 区域选取：如Sliding Windows
2. 特征提取：如SIFT和HOG等
3. 特征分类：如SVM、AdaBoost等

# 评价指标

IoU的计算：

```python
def iou(boxA, boxB):
    # 计算重合部分的上、下、左、右4个边的值，注意最大最小函数的使用
    left_max = max(boxA[0], boxB[0])
    top_max = max(boxA[1], boxB[1])
    right_min = min(boxA[2], boxB[2])
    bottom_min = min(boxA[3], boxB[3])
    # 计算重合部分的面积
    inter = max(0, (right_min-left_max)) * max(0,(bottom_min-top_max))
    Sa = (boxA[2]-boxA[0]) * (boxA[3] - boxA[1])
    Sb = (boxB[2]-boxB[0]) * (boxB[3] - boxB[1])
    union = Sa + Sb - inter
    iou = inter / union
    return iou    
```

对于IoU而言，大于0.5时通常才认为是一个有效的检测。

​	![image-20210706152308420](C:/Users/user/AppData/Roaming/Typora/typora-user-images/image-20210706152308420.png)

由于图像中存在背景与物品两种标签，预测框也分为正确与错误，因此在评测时会产生以下4中样本：

+ 正确检测框TP（True Positive）:正确的，如图
+ 误检框FP（False Positive）:将背景预测成了物体
+ 漏检框FN（False Negative）:本来需要检测出的物体没有检测出
+ 正确背景TN（True Negative）：本身是背景，模型也没有检测出来

# mAP（Mean Average Precision）

AP指的是一个类别的检测精度，mAP是多个类别的平均精度

+ 预测值（Dets）：物体类别、边框位置的4个预测值、该物体的得分
+ 标签值（GTs）:物体类别，边框位置的4个真值

# Recall, R

当前一共检测出的标签框与所有标签框的比值

# Precision, P

当前遍历过的预测框中，属于正确预测框的比值

# P-R Curve

遍历到每一个预测框时，都可以生成一个对应的P和R，将所有的点绘制成曲线，就成了P-R曲线。

![image-20210706154001423](https://raw.githubusercontent.com/by777/imgRep/main/img/20210706154001.png)

但如果直接选取曲线上的点，召回率高的时候准确率很低，准确率高的时候召回率很低。这时使用


$$
AP = ∫^1_0PdR
$$


# 常用工具

+ apt install terminator

+ apt install screen

  | 操作            | 含义                       |
  | :-------------- | :------------------------- |
  | screen -S name  | 新建一个叫name的窗口       |
  | ctrl+a->ctrl+d  | 关闭当前的Screen窗口       |
  | ctrl+a->k->y    | 永久性删除当前的Screen窗口 |
  | screen -ls      | 列举所有当前的Screen窗口   |
  | screen - r name | 回到name窗口               |

  

