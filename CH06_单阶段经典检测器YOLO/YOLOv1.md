# YOLO v1

+ 时间：2015

YOLO v1将输入图像划分为7 x 7的区域，每一区域对应最后特征图上的一个点，该点的通道数为30，代表了预测的30个特征。

YOLO v1在每一个区域预测了两个框，这样整个图上一共预测7 x 7 x 2 = 98个框，这些框的大小与位置各不相同，基本可以覆盖整个图上可能出现的物体。

![image-20210721153638774](https://raw.githubusercontent.com/by777/imgRep/main/img/20210721153639.png)

如果一个物体的中心点落在了某个区域内，就由该区域负责检测该物体。如图，真实物体框的中心点在当前区域内，该区域就负责检测该物体，具体做法是将该区域的两个框与真实物体框相匹配，IoU更大的框负责回归该真实物体框，在此A框更接近真实物体。

最终的预测特征由类别概率、边框的置信度及边框的位置组成。如图，这3者的含义如下：

+ 类别概率。由于PASCAL VOC数据集一共有20个物体类别，因此这里预测的是物体属于哪一类别。
+ 置信度。由于有两个框，因此会存在两个置信度预测值。
+ 边框位置。对每一个边框需要预测其中心坐标及w、h。两个框共计8个预测值。

![image-20210721155302672](https://raw.githubusercontent.com/by777/imgRep/main/img/20210721155302.png)

注意：YOLO v1采用了物体类别与置信度分开的预测方法，这点与Faster RCNN不同，Faster RCNN将背景也当作了一个类别，共计21种，在类别预测种包含了置信度的预测。

# 损失计算

通过CNN得到每个边框的预测值后为了进一步计算网络训练的损失，还需要确定每一个边框对应的是真实物体还是背景框，即区分正、负样本。YOLO v1在确定正负样本时，有以下两个原则：

+ 
